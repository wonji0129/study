{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking and padding with Keras\n",
    "- Masking: 데이터가 누락되었을 때 이를 건너뛰고 처리하도록 하는 방식 (sequence data -> 누락된 시점을 건너뛰도록 함)\n",
    "- Padding: a special form of masking where the masked steps are at the start or at the beginning of a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample마다 데이터 길이가 다른 경우가 종종 있음\n",
    "- 딥러닝 모델 input 데이터는 단일 shape이므로 -> 길이가 짧은 샘플은 패딩 처리 \n",
    "- tf.keras.preprocessing.sequence.pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 711  632   71    0    0    0]\n",
      " [  73    8 3215   55  927    0]\n",
      " [  83   91    1  645 1253  927]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    [711, 632, 71], # 길이 3\n",
    "    [73, 8, 3215, 55, 927], # 길이 5\n",
    "    [83, 91, 1, 645, 1253, 927], # 길이 6\n",
    "]\n",
    "\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        raw_inputs, padding='post' # pre or post 둘 중 하나 선택 가능 -> post 추천\n",
    ")\n",
    "print(padded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 생성 시, input data가 Padding 되었음을 알려야 함 -> 그래야 padding된 데이터를 무시할 수 있으므로 (masking)\n",
    "- keras.layers.Masking\n",
    "- keras.layers.Embeddin w/ mask_zero=True\n",
    "- pass a 'mask' argument manually..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask tensor (2D tensor with shape - (batch, sequence_length))\n",
    "embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "masked_output = embedding(padded_inputs)\n",
    "\n",
    "masking_layer = layers.Masking()\n",
    "unmasked_embedding = tf.cast( # expanding 2D input to 3D \n",
    "    tf.tile(tf.expand_dims(padded_inputs, axis=-1), [1, 1, 10]), tf.float32\n",
    ")\n",
    "\n",
    "masked_embedding = masking_layer(unmasked_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 6), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, False, False, False],\n",
       "       [ True,  True,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding input을 Embedding하거나 Masking하면 mask 값도 같이 전달\n",
    "masked_output._keras_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 6), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, False, False, False],\n",
       "       [ True,  True,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embedding._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a mask generated by an Embedding or Masking layer -> 어느 레이어에서도 활용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True), # Embedding 레이어에서 알아서 Padding\n",
    "    layers.LSTM(32)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API\n",
    "inputs = keras.Input(shape=(None,), dtype='int32')\n",
    "x = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)(inputs)  # Embedding 레이어에서 알아서 Padding\n",
    "outputs = layers.LSTM(32)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing mask tensors directly to layers\n",
    "- LSTM 같은 레이어(mask-consuming layer)에서는 __call__ 메서드에 mask를 argument로 주어 직접 다룰 수 있음\n",
    "- Embedding 같은 레이어(mask-producing layer)에서는 mask를 만듦 -> compute_mask(input, previous mask) 메서드를 LTST 레이어에 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 32), dtype=float32, numpy=\n",
       "array([[-5.0492650e-03,  1.0275564e-03, -1.5185910e-03, ...,\n",
       "        -3.2672107e-03,  1.2886111e-03, -1.5768912e-03],\n",
       "       [-8.9791315e-03,  1.5349587e-03,  3.8674767e-03, ...,\n",
       "         3.2387141e-03, -1.6375385e-04,  1.5844356e-03],\n",
       "       [-3.3967171e-04,  1.5671948e-03, -7.3049875e-04, ...,\n",
       "         3.5871912e-03, -7.8019494e-04, -2.8426962e-03],\n",
       "       ...,\n",
       "       [ 1.2105663e-03,  1.2680746e-03, -4.0347474e-03, ...,\n",
       "        -1.2906976e-03,  8.3061773e-04, -4.2560901e-03],\n",
       "       [-4.4841692e-03,  2.2434755e-03,  4.8386324e-03, ...,\n",
       "         2.9819105e-03,  6.5205015e-05,  3.2284940e-03],\n",
       "       [ 7.7692280e-04,  5.7852559e-04,  1.1240725e-03, ...,\n",
       "         7.0996182e-03, -3.2469053e-03,  2.2084371e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "        self.embedding = layers.Embedding(input_dim=5000, output_dim=6, mask_zero=True)\n",
    "        self.lstm = layers.LSTM(32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        mask = self.embedding.compute_mask(inputs)\n",
    "        output = self.lstm(x, mask=mask)\n",
    "        return output\n",
    "    \n",
    "layer = MyLayer()\n",
    "x = np.random.random((32, 10)) * 100\n",
    "x = x.astype('int32')\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalSplit(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        return tf.split(inputs, 2, axis=1)\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if mask is None:\n",
    "            return None\n",
    "        return tf.split(mask, 2, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]], shape=(3, 3), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[False False False]\n",
      " [ True  True False]\n",
      " [ True  True  True]], shape=(3, 3), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "first_half, second_half = TemporalSplit()(masked_embedding)\n",
    "print(first_half._keras_mask)\n",
    "print(second_half._keras_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, input_dim, output_dim, mask_zero=False, **kwargs):\n",
    "        super(CustomEmbedding, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.mask_zero = mask_zero\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.embeddings = self.add_weight(\n",
    "            shape=(self.input_dim, self.output_dim),\n",
    "            initializer='random_normal',\n",
    "            dtype='float32'\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.embedding_lookup(self.embeddings, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "layer = CustomEmbedding(10, 32, mask_zero=True)\n",
    "x = np.random.random((3, 10)) * 9\n",
    "x = x.astype(\"int32\")\n",
    "\n",
    "y = layer(x)\n",
    "mask = layer.compute_mask(x)\n",
    "\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask found: KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.bool, name=None), name='Placeholder_1:0')\n"
     ]
    }
   ],
   "source": [
    "class MyActivation(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyActivation, self).__init__(**kwargs)\n",
    "        # Signal that the layer is safe for mask propagation\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.relu(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "x = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)(inputs)\n",
    "x = MyActivation()(x)  # supports_masking = True\n",
    "print(\"Mask found:\", x._keras_mask)\n",
    "outputs = layers.LSTM(32)(x)  # Will receive the mask\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalSoftmax(keras.layers.Layer):\n",
    "    def call(self, inputs, mask=None):\n",
    "        broadcast_float_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\n",
    "        inputs_exp = tf.exp(inputs) * broadcast_float_mask\n",
    "        inputs_sum = tf.reduce_sum(inputs * broadcast_float_mask, axis=1, keepdims=True)\n",
    "        return inputs_exp / inputs_sum\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "x = layers.Embedding(input_dim=10, output_dim=32, mask_zero=True)(inputs)\n",
    "x = layers.Dense(1)(x)\n",
    "outputs = TemporalSoftmax()(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "y = model(np.random.randint(0, 10, size=(32, 100)), np.random.random((32, 100, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
