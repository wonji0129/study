{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미리 만들어진 에스티 메이터\n",
    "- https://www.tensorflow.org/tutorials/estimator/premade?hl=ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.estimator: 고수준 TensorFlow API \n",
    "- 전체 모델에 대한 TensorFlow의 고수준 표현이며(a model-level abstraction) 손쉬운 확장 및 비동기 학습을 위해 설계\n",
    "- TF에서 훈련 / 평가 / 에측 / 서빙내보내기를 encapsulate해서 만들어놓은 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train_path = tf.keras.utils.get_file( # local path, download url\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimator: tf.estimator.Estimator 에서 파생 된 모든 클래스\n",
    "- tf.estimator 모음에서 일반적인 ML 알고리즘을 구현해놓음 (예 : LinearRegressor)\n",
    "- 그 외에도 사용자 정의 Estimators를 작성할 수 있습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator 이용한 TF 프로그램?\n",
    "- 하나 이상의 입력 함수를 만듭니다.\n",
    "- 모델의 특성 열을 정의합니다.\n",
    "- 특성 열과 다양한 하이퍼 파라미터를 지정하여 에스티 메이터를 인스턴스화합니다.\n",
    "- Estimator 개체에서 하나 이상의 메서드를 호출하여 적절한 입력 함수를 데이터 소스로 전달합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 함수: tf.data.Dataset 객체를 반환하는 함수\n",
    "- features: python dictionary\n",
    "- label: 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_evaluation_set(): # 입력함수 형태 보여주는 예시함수 \n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "                'SepalWidth':  np.array([2.8, 2.3]),\n",
    "                'PetalLength': np.array([5.6, 3.3]),\n",
    "                'PetalWidth':  np.array([2.2, 1.0])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 종류의 데이터를 위 형태로 파싱하는 TF의 API 이용해도 됨\n",
    "- https://www.tensorflow.org/guide/data?hl=ko\n",
    "- tf.data.Dataset: 병렬로 읽고 단일 스트림으로 결합 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas로 데이터를로드하고 인-메모리 데이터에서 입력 파이프 라인을 빌드합니다.\n",
    "\n",
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature dictionary의 raw input data를 사용하는 방법을 설명하는 개체\n",
    "# tf.feature_column 모듈 \n",
    "\n",
    "my_feature_columns = []\n",
    "for k in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/1c/xhkpty0142l7xwkrqtm3t9p80000gn/T/tmpljr47y3b\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/1c/xhkpty0142l7xwkrqtm3t9p80000gn/T/tmpljr47y3b', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate esimator\n",
    "# - 예시: tf.estimator.DNNClassifier, DNNLinearCombindClassifier, LinearClassifier\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns, # feature 특성\n",
    "    hidden_units=[30, 10],\n",
    "    n_classes=3 # 문제 정의\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/wonji/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/wonji/.pyenv/versions/3.7.7/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:83: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/1c/xhkpty0142l7xwkrqtm3t9p80000gn/T/tmpljr47y3b/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.3187697, step = 0\n",
      "INFO:tensorflow:global_step/sec: 550.749\n",
      "INFO:tensorflow:loss = 0.985477, step = 100 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.846\n",
      "INFO:tensorflow:loss = 0.90403473, step = 200 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 749.719\n",
      "INFO:tensorflow:loss = 0.8622308, step = 300 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.847\n",
      "INFO:tensorflow:loss = 0.82984275, step = 400 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 739.66\n",
      "INFO:tensorflow:loss = 0.81309, step = 500 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 783.393\n",
      "INFO:tensorflow:loss = 0.79443645, step = 600 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 745.7\n",
      "INFO:tensorflow:loss = 0.7735996, step = 700 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 791.922\n",
      "INFO:tensorflow:loss = 0.7549464, step = 800 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 762.404\n",
      "INFO:tensorflow:loss = 0.7510663, step = 900 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 766.724\n",
      "INFO:tensorflow:loss = 0.7116512, step = 1000 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.929\n",
      "INFO:tensorflow:loss = 0.6850543, step = 1100 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 765.468\n",
      "INFO:tensorflow:loss = 0.6759231, step = 1200 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 759.762\n",
      "INFO:tensorflow:loss = 0.6613766, step = 1300 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 766.378\n",
      "INFO:tensorflow:loss = 0.6496197, step = 1400 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 759.573\n",
      "INFO:tensorflow:loss = 0.64304423, step = 1500 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 724.978\n",
      "INFO:tensorflow:loss = 0.6568309, step = 1600 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 734.365\n",
      "INFO:tensorflow:loss = 0.6445421, step = 1700 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 780.355\n",
      "INFO:tensorflow:loss = 0.62861073, step = 1800 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 742.595\n",
      "INFO:tensorflow:loss = 0.6064215, step = 1900 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 738.711\n",
      "INFO:tensorflow:loss = 0.6087458, step = 2000 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 788.319\n",
      "INFO:tensorflow:loss = 0.594935, step = 2100 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.646\n",
      "INFO:tensorflow:loss = 0.5660628, step = 2200 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 782.674\n",
      "INFO:tensorflow:loss = 0.5923572, step = 2300 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 767.86\n",
      "INFO:tensorflow:loss = 0.5703589, step = 2400 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 742.133\n",
      "INFO:tensorflow:loss = 0.55639476, step = 2500 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 773.203\n",
      "INFO:tensorflow:loss = 0.5516769, step = 2600 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 736.658\n",
      "INFO:tensorflow:loss = 0.55437124, step = 2700 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 783.35\n",
      "INFO:tensorflow:loss = 0.543413, step = 2800 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 756.213\n",
      "INFO:tensorflow:loss = 0.5169269, step = 2900 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 729.835\n",
      "INFO:tensorflow:loss = 0.5299852, step = 3000 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 753.825\n",
      "INFO:tensorflow:loss = 0.5288335, step = 3100 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 756.344\n",
      "INFO:tensorflow:loss = 0.51744854, step = 3200 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 765.101\n",
      "INFO:tensorflow:loss = 0.51719576, step = 3300 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 774.058\n",
      "INFO:tensorflow:loss = 0.5121347, step = 3400 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 733.825\n",
      "INFO:tensorflow:loss = 0.48867035, step = 3500 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 750.758\n",
      "INFO:tensorflow:loss = 0.49566627, step = 3600 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 768.38\n",
      "INFO:tensorflow:loss = 0.49307215, step = 3700 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 744.114\n",
      "INFO:tensorflow:loss = 0.47924623, step = 3800 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 737.958\n",
      "INFO:tensorflow:loss = 0.47293347, step = 3900 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 767.978\n",
      "INFO:tensorflow:loss = 0.49938965, step = 4000 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 740.072\n",
      "INFO:tensorflow:loss = 0.46376723, step = 4100 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.964\n",
      "INFO:tensorflow:loss = 0.47379398, step = 4200 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.464\n",
      "INFO:tensorflow:loss = 0.46527588, step = 4300 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.733\n",
      "INFO:tensorflow:loss = 0.46505815, step = 4400 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 764.987\n",
      "INFO:tensorflow:loss = 0.45164675, step = 4500 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.296\n",
      "INFO:tensorflow:loss = 0.45371872, step = 4600 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.998\n",
      "INFO:tensorflow:loss = 0.45898953, step = 4700 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.366\n",
      "INFO:tensorflow:loss = 0.44156754, step = 4800 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 749.003\n",
      "INFO:tensorflow:loss = 0.4476325, step = 4900 (0.133 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/1c/xhkpty0142l7xwkrqtm3t9p80000gn/T/tmpljr47y3b/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.43088084.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x160560fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimator는 훈련, 평가, 예측 메서드를 포함\n",
    "\n",
    "# 훈련\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    # 인-메모리 데이터에 배치로 처리된 입력 파이프라인\n",
    "    steps=5000\n",
    ")\n",
    "# 인수를 사용하지 않는 입력 함수를 제공하면서 인수를 캡처하기 위해 input_fn 호출을 lambda 로 래핑합니다. ???\n",
    "# steps 인수는 여러 훈련 단계 후에 훈련을 중지하는 방법을 알려줍니다.???? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-01-07T23:37:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/1c/xhkpty0142l7xwkrqtm3t9p80000gn/T/tmpljr47y3b/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.22893s\n",
      "INFO:tensorflow:Finished evaluation at 2021-01-07-23:37:06\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.7, average_loss = 0.5410508, global_step = 5000, loss = 0.5410508\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/1c/xhkpty0142l7xwkrqtm3t9p80000gn/T/tmpljr47y3b/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, batch_size=256): # label이 없는 입력함수\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features).batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x162699c50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/1c/xhkpty0142l7xwkrqtm3t9p80000gn/T/tmpljr47y3b/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (82.2%), expected \"Setosa\"\n",
      "Prediction is \"Virginica\" (46.8%), expected \"Versicolor\"\n",
      "Prediction is \"Virginica\" (66.8%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
